{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "addc6c8b",
   "metadata": {},
   "source": [
    "### Q-8. Quora question pair similarity, you need to find the Similarity between two questions by mapping the words in the questions using TF-IDF, and using a supervised Algorithm you need to find the similarity between the questions. Dataset This is the Dataset You can use this dataset for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e93bb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c766c0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9daf3357",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f94189a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in share market in india?</td>\n",
       "      <td>What is the step by step guide to invest in share market?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Diamond?</td>\n",
       "      <td>What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet connection while using a VPN?</td>\n",
       "      <td>How can Internet speed be increased by hacking through DNS?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve it?</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] is divided by 24,23?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt, methane and carbon di oxide?</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2  \\\n",
       "0   0     1     2   \n",
       "1   1     3     4   \n",
       "2   2     5     6   \n",
       "3   3     7     8   \n",
       "4   4     9    10   \n",
       "\n",
       "                                                                      question1  \\\n",
       "0            What is the step by step guide to invest in share market in india?   \n",
       "1                           What is the story of Kohinoor (Koh-i-Noor) Diamond?   \n",
       "2     How can I increase the speed of my internet connection while using a VPN?   \n",
       "3                            Why am I mentally very lonely? How can I solve it?   \n",
       "4  Which one dissolve in water quikly sugar, salt, methane and carbon di oxide?   \n",
       "\n",
       "                                                                                  question2  \\\n",
       "0                                 What is the step by step guide to invest in share market?   \n",
       "1  What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back?   \n",
       "2                               How can Internet speed be increased by hacking through DNS?   \n",
       "3                         Find the remainder when [math]23^{24}[/math] is divided by 24,23?   \n",
       "4                                                   Which fish would survive in salt water?   \n",
       "\n",
       "   is_duplicate  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d79bc20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "847ceb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(100000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82ebccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"id\", \"qid1\", \"qid2\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b3c422f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question1       0\n",
       "question2       0\n",
       "is_duplicate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4c3715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e23b27fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>How do I play Pokémon GO in Korea?</td>\n",
       "      <td>How do I play Pokémon GO in China?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368101</th>\n",
       "      <td>What are some of the best side dishes for crab cakes?</td>\n",
       "      <td>What are some good side dishes for buffalo chicken?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70497</th>\n",
       "      <td>Which is more advisable and better material for a crash test in automobiles, ductile or brittle?</td>\n",
       "      <td>What is the best server setup for buddypress?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226567</th>\n",
       "      <td>How do I improve logical programming skills?</td>\n",
       "      <td>How can I improve my logical skills for programming?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73186</th>\n",
       "      <td>How close we are to see 3rd world war?</td>\n",
       "      <td>How close is a World War III?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                               question1  \\\n",
       "8067                                                                  How do I play Pokémon GO in Korea?   \n",
       "368101                                             What are some of the best side dishes for crab cakes?   \n",
       "70497   Which is more advisable and better material for a crash test in automobiles, ductile or brittle?   \n",
       "226567                                                      How do I improve logical programming skills?   \n",
       "73186                                                             How close we are to see 3rd world war?   \n",
       "\n",
       "                                                   question2  is_duplicate  \n",
       "8067                      How do I play Pokémon GO in China?             0  \n",
       "368101   What are some good side dishes for buffalo chicken?             0  \n",
       "70497          What is the best server setup for buddypress?             0  \n",
       "226567  How can I improve my logical skills for programming?             1  \n",
       "73186                          How close is a World War III?             1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abdb7d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aneesaro/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/aneesaro/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/aneesaro/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/aneesaro/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9aead2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_object(file_path):\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            return pickle.load(file)\n",
    "    except Exception as err:\n",
    "        raise CustomException(sys, err)\n",
    "\n",
    "\n",
    "# Define a function to map the part of speech tags from NLTK to WordNet\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character used by WordNet lemmatizer\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def message_text_process(mess):\n",
    "    mess = remove_word_with_digit_and_non_ascii(mess)\n",
    "    # remove punctuation from string\n",
    "    no_punctuation = [char for char in mess if char not in string.punctuation]\n",
    "    no_punctuation = ''.join(no_punctuation)  # joining all the characters without punctuation\n",
    "    # remove stop words\n",
    "    words = [word.lower() for word in no_punctuation.split() if word not in stopwords.words('english')]\n",
    "    words = \" \".join(words)\n",
    "    # lemmatize the text\n",
    "    tokens = nltk.word_tokenize(words)\n",
    "    lemmas = []\n",
    "    for token in tokens:\n",
    "        lemma = lemmatizer.lemmatize(token, pos=get_wordnet_pos(token))\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "\n",
    "def remove_word_with_digit_and_non_ascii(sentence):\n",
    "    final_sentence = \"\"\n",
    "    sentence = ''.join(c for c in sentence if ord(c) < 128)\n",
    "    for word in sentence:\n",
    "        if not any(char.isdigit() for char in word):\n",
    "            final_sentence += word\n",
    "    return final_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "575c0bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer  # import Count Vectorizer to create DTM\n",
    "from sklearn.feature_extraction.text import TfidfTransformer  # import to convert DTM to TF-IDF\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "count_vectorized = CountVectorizer(analyzer=message_text_process)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "text_pipeline = Pipeline(steps=[\n",
    "    (\"bag\", count_vectorized),\n",
    "    (\"ttfidf\", tfidf_transformer)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5338d016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee30c8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"is_duplicate\"], axis=1)\n",
    "y = df[\"is_duplicate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33dcfa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b61393c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question1_train = text_pipeline.fit_transform(X_train[\"question1\"])\n",
    "question2_train = text_pipeline.transform(X_train[\"question2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41d29b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "question1_test = text_pipeline.transform(X_test[\"question1\"])\n",
    "question2_test = text_pipeline.transform(X_test[\"question2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ee8926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "train_arr = sparse.hstack((question1_train, question2_train))\n",
    "test_arr = sparse.hstack((question1_test, question2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4347c96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]....................................................................................................*........................................*\n",
      "optimization finished, #iter = 140766\n",
      "obj = -10677.829722, rho = -0.623198\n",
      "nSV = 59268, nBSV = 2608\n",
      "Total nSV = 59268\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svc = svm.SVC(kernel='poly', coef0=0.5, degree=3, verbose=True).fit(train_arr, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8132f8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc.predict(test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ef66eaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84     18847\n",
      "           1       0.75      0.66      0.70     11153\n",
      "\n",
      "    accuracy                           0.79     30000\n",
      "   macro avg       0.78      0.76      0.77     30000\n",
      "weighted avg       0.79      0.79      0.79     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "aba06c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "class_prior = [0.7, 0.7]\n",
    "\n",
    "nb = MultinomialNB(alpha=1, class_prior=class_prior).fit(train_arr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9a2d871e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nb.predict(test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "57bf1b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77     18847\n",
      "           1       0.62      0.62      0.62     11153\n",
      "\n",
      "    accuracy                           0.71     30000\n",
      "   macro avg       0.69      0.69      0.69     30000\n",
      "weighted avg       0.71      0.71      0.71     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "91ee6f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"model.pkl\", \"wb\") as file_obj:\n",
    "    pickle.dump(svc, file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39486c21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
